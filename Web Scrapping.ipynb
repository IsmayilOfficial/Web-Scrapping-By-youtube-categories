{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from selenium) (1.25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas) (1.16.4)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "import pandas as pd \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.youtube.com/results?search_query=travel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "    if i.get_attribute('href') is not None:\n",
    "        links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))\n",
    "#//*[@id=\"video-title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"Travel\"\n",
    "for x in links:\n",
    "    driver.get(x)\n",
    "    v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "    v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "    v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "    df.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.youtube.com/results?search_query=science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "    if i.get_attribute('href') is not None:\n",
    "        links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_science = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"Science\"\n",
    "for x in links:\n",
    "    driver.get(x)\n",
    "    v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "    v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "    v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "    df_science.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.youtube.com/results?search_query=History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "    if i.get_attribute('href') is not None:\n",
    "        links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"History\"\n",
    "for x in links:\n",
    "    driver.get(x)\n",
    "    v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "    v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "    v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "    df_history.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.youtube.com/results?search_query=menufacturing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "    if i.get_attribute('href') is not None:\n",
    "        links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l=[]\n",
    "#for i in range(len(links)):\n",
    "#    if links[i] is not None:\n",
    "#        l.append(links[i])\n",
    "#l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_menufacturing = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"Menufacturing\"\n",
    "for x in links:\n",
    "    driver.get(x)\n",
    "    v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "    v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "    v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "    df_menufacturing.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.youtube.com/results?search_query=Art and Music \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "    if i.get_attribute('href') is not None:\n",
    "        links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artndance  = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"Art and Music \"\n",
    "for x in links:\n",
    "    driver.get(x)\n",
    "    v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "    v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "    v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "    df_artndance.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.youtube.com/results?search_query=Food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "user_data = driver.find_elements_by_xpath('//*[@id=\"video-title\"]')\n",
    "links = []\n",
    "for i in user_data:\n",
    "    if i.get_attribute('href') is not None:\n",
    "        links.append(i.get_attribute('href'))\n",
    "\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food  = pd.DataFrame(columns = ['link', 'title', 'description', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)\n",
    "v_category = \"Food\"\n",
    "for x in links:\n",
    "    driver.get(x)\n",
    "    v_id = x.strip('https://www.youtube.com/watch?v=')\n",
    "    v_title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "    v_description =  wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"div#description yt-formatted-string\"))).text\n",
    "    df_food.loc[len(df)] = [v_id, v_title, v_description, v_category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df, df_science, df_food, df_menufacturing, df_history, df_artndance]\n",
    "df_copy = pd.concat(frames, axis=0, join='outer', join_axes=None, ignore_index=True,keys=None, levels=None, names=None, verify_integrity=False, sort=None,copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_link = pd.DataFrame(columns = [\"link\"])        \n",
    "df_title = pd.DataFrame(columns = [\"title\"])        \n",
    "df_description = pd.DataFrame(columns = [\"description\"])        \n",
    "df_category = pd.DataFrame(columns = [\"category\"])        \n",
    "df_link['link'] = df_copy['link'] \n",
    "df_title ['title']= df_copy['title'] \n",
    "df_description['description'] = df_copy['description'] \n",
    "df_category['category'] = df_copy['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import nltk \n",
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         200 Days - A Trip Around the World Travel Film\n",
       "1      Ep 1| Travelling through North East India | Of...\n",
       "2                Iceland Vacation Travel Guide | Expedia\n",
       "3        How do I travel so much ! How do I earn money!!\n",
       "4       10 Best Places to Visit in Norway - Travel Video\n",
       "5      We Are SURPRISED | First Impressions of Sri La...\n",
       "6      Why Indians Go to Pattaya ? Thailand Travel vl...\n",
       "7      How to travel the world with almost no money |...\n",
       "8      Meghalaya Tourism Video | NorthEast India | Ca...\n",
       "9      TRAVEL HACKS THAT WILL DIVIDE YOUR LIFE INTO B...\n",
       "10                           28 CRAZY SMART TRAVEL HACKS\n",
       "11     Don Bosco Museum & Scenic Shillong Bypass Driv...\n",
       "12     When I Travel to Pathan bhai's Home|| India Vs...\n",
       "13     7 Cheapest Countries in the World to travel - ...\n",
       "14     Top 7 INCREDIBLE Travel Destinations of 2019 |...\n",
       "15     Top ten cheapest countries to travel from Indi...\n",
       "16     Welcome to Peru! | Best Essential Tips & Trave...\n",
       "17     Discovering Unseen Sri Lanka ðŸ‡±ðŸ‡° | Colombo to J...\n",
       "18     Travel More & Buy Less. | Luis Vargas | TEDxPo...\n",
       "19     31 INSANELY AFFORDABLE Budget Travel Destinati...\n",
       "20         EGYPT & JORDAN | Ep2: Solo Backpacking Jordan\n",
       "21     25 Best Places to Visit in Europe - Travel Europe\n",
       "22          Travel: Expectation V/s Reality | MostlySane\n",
       "23                 How to Travel INDIA - but is it safe?\n",
       "24     Travel Hacks|à¤­à¥à¤² à¤•à¤° à¤•à¤° à¤­à¥€ à¤¯à¥‡ à¤—à¤²à¤¤à¤¿à¤¯à¤¾à¤ Travelà¤•à¤°à¤¤...\n",
       "25                                 Three YEARS of Travel\n",
       "26                     Delhi Vacation Travel Video Guide\n",
       "27     Trongsa - Bumthang Valley, A heavenly drive to...\n",
       "28            PARADISE - PHILIPPINES TRAVEL - GOPRO TRIP\n",
       "29                       HOW TO TRAVEL AMSTERDAM in 2019\n",
       "                             ...                        \n",
       "158    10 Best Places to Visit in Germany - Travel Video\n",
       "159    Fuzhou - China's Untouched City - Smart Travel...\n",
       "160    How To Make a TRAVEL VIDEO - 10 Tips you need ...\n",
       "161    ðŸ‡¨ðŸ‡¦ VANCOUVER Travel Guide ðŸ‡¨ðŸ‡¦ | Travel Better i...\n",
       "162    10 Best Places to Visit in South Africa - Trav...\n",
       "163    How Expensive is it to Travel Japan? | Budget ...\n",
       "164                  Is Time Travel Possible? | Unveiled\n",
       "165    15 Things They Don't Tell You About Traveling ...\n",
       "166                 Top Time Travel Japanese Dramas 2018\n",
       "167                10 MYSTERIOUS EVIDENCE OF TIME TRAVEL\n",
       "168               Thailand Travel Guide and Tourism (HD)\n",
       "169                       [MV] BOL4(ë³¼ë¹¨ê°„ì‚¬ì¶˜ê¸°) _ Travel(ì—¬í–‰)\n",
       "170         Travel(ì—¬í–‰) - Bol4(ë³¼ë¹¨ê°„ì‚¬ì¶˜ê¸°) / Beginner's Class\n",
       "171                Paris Vacation Travel Guide | Expedia\n",
       "172             Portland Vacation Travel Guide | Expedia\n",
       "173    Roblox : Time Travel Adventures #2 (Sub Zero)(...\n",
       "174    11 Travel Hacks Everyone Should Know! Clever &...\n",
       "175            Vancouver Vacation Travel Guide | Expedia\n",
       "176                                  Berlin Travel Guide\n",
       "177    10 Must Know JAPAN Travel Tips No One Talks ab...\n",
       "178                   32 Airport & Airplane Travel Hacks\n",
       "179    Cusco Travel Guide | The Ancient Inca Capital ...\n",
       "180    [BOL4 - Travel] Comeback Stage | M COUNTDOWN 1...\n",
       "181            Patagonia Vacation Travel Guide | Expedia\n",
       "182     10 Best Places to Visit in Canada - Travel Video\n",
       "183    How STRONG is the Smash Bros Home Run Bat? | T...\n",
       "184                        Street Food in Italy - Sicily\n",
       "185                        Handling Manufacturing Delays\n",
       "186                       A Brief History of Timekeeping\n",
       "187                        Music, Painting, Art for kids\n",
       "Name: title, Length: 188, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []        \n",
    "for i in range(0, 187):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df_title['title'][2])            \n",
    "    review = review.lower()            \n",
    "    review = review.split()            \n",
    "    ps = PorterStemmer()            \n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]            \n",
    "    review = ' '.join(review)            \n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = [] \n",
    "for i in range(0, 187):            \n",
    "  review = re.sub('[^a-zA-Z]', ' ', df_description['description'][i])            \n",
    "  review = review.lower()            \n",
    "  review = review.split()            \n",
    "  ps = PorterStemmer()            \n",
    "  review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]            \n",
    "  review = ' '.join(review)            \n",
    "  corpus1.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftitle = pd.DataFrame({'title':corpus})\n",
    "dfdescription = pd.DataFrame({'description':corpus1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn (from sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/1b/969bc7bf9851b8b05a81721103d6ac9f656d4cdef90a68da96686245c69c/scikit_learn-0.21.2-cp37-cp37m-win32.whl (5.2MB)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from scikit-learn->sklearn) (1.16.4)\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "Collecting scipy>=0.17.0 (from scikit-learn->sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/be/cc/6f7842a4d9aa7f51155f849185631e1201df255742de84d724ac33bff723/scipy-1.3.0-cp37-cp37m-win32.whl (27.1MB)\n",
      "Installing collected packages: joblib, scipy, scikit-learn, sklearn\n",
      "  Running setup.py install for sklearn: started\n",
      "    Running setup.py install for sklearn: finished with status 'done'\n",
      "Successfully installed joblib-0.13.2 scikit-learn-0.21.2 scipy-1.3.0 sklearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "dfcategory = df_category.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_link, dftitle, dfdescription, dfcategory], axis=1, join_axes = [df_link.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'data_frame.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "cv = CountVectorizer(max_features = 1500) \n",
    "X = cv.fit_transform(corpus, corpus1).toarray() \n",
    "y = df_new.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y[0:187], test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred1 = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred2 = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    " print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "clf = HistGradientBoostingClassifier().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "y_pred3 = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train, y_train)  \n",
    "y_pred4 = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
